2026-02-20 22:56:19 [scrapy.utils.log] INFO: Scrapy 2.14.1 started (bot: aoty_crawler)
2026-02-20 22:56:19 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.11.9',
 'cssselect': '1.4.0',
 'parsel': '1.11.0',
 'w3lib': '2.4.0',
 'Twisted': '25.5.0',
 'Python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.5 27 Jan 2026)',
 'cryptography': '46.0.5',
 'Platform': 'Windows-10-10.0.19045-SP0'}
2026-02-20 22:56:19 [production] INFO: 
============================================================
2026-02-20 22:56:19 [production] INFO: PRODUCTION SPIDER CONFIGURATION
2026-02-20 22:56:19 [production] INFO: ============================================================
2026-02-20 22:56:19 [production] INFO: Target Genre: ALL GENRES
2026-02-20 22:56:19 [production] INFO: Year Range: 2026 to 2026
2026-02-20 22:56:19 [production] INFO: Albums per Year: 2
2026-02-20 22:56:19 [production] INFO: Test Mode: True
2026-02-20 22:56:19 [production] INFO: ============================================================

2026-02-20 22:56:19 [scrapy.addons] INFO: Enabled addons:
[]
2026-02-20 22:56:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logcount.LogCount',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2026-02-20 22:56:19 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 10,
 'AUTOTHROTTLE_START_DELAY': 3,
 'BOT_NAME': 'aoty_crawler',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 3,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '-',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'aoty_crawler.spiders',
 'RETRY_HTTP_CODES': [500, 502, 503, 504, 522, 524, 408, 429, 403],
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['aoty_crawler.spiders'],
 'TELNETCONSOLE_ENABLED': False,
 'USER_AGENT': 'AOTY-Production-Spider/1.0 (Music Data Collection)'}
2026-02-20 22:56:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'aoty_crawler.middlewares.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'aoty_crawler.middlewares.RetryWithDelayMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:44: ScrapyDeprecationWarning: SeleniumMiddleware.process_request() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_request)

2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:47: ScrapyDeprecationWarning: RetryWithDelayMiddleware.process_response() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_response)

2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:50: ScrapyDeprecationWarning: RetryWithDelayMiddleware.process_exception() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_exception)

2026-02-20 22:56:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2026-02-20 22:56:19 [scrapy.middleware] INFO: Enabled item pipelines:
['aoty_crawler.pipelines.FileStoragePipeline',
 'aoty_crawler.pipelines.DuplicateCheckPipeline']
2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:44: ScrapyDeprecationWarning: FileStoragePipeline.close_spider() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.close_spider)

2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:47: ScrapyDeprecationWarning: FileStoragePipeline.process_item() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.process_item)

2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:47: ScrapyDeprecationWarning: DuplicateCheckPipeline.process_item() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.process_item)

2026-02-20 22:56:19 [scrapy.core.engine] INFO: Spider opened
2026-02-20 22:56:19 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\spidermw.py:490: ScrapyDeprecationWarning: aoty_crawler.spiders.production_spider.ProductionSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2026-02-20 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2026-02-20 22:56:19 [production] INFO: Starting at genre page: https://www.albumoftheyear.org/genre.php
2026-02-20 22:56:24 [production] INFO: Parsing genre page: https://www.albumoftheyear.org/genre.php
2026-02-20 22:56:24 [production] INFO: Found 89 genre links
2026-02-20 22:56:24 [production] INFO: Found genre: Rock (slug: rock)
2026-02-20 22:56:24 [production] INFO:   → Year 2026: https://www.albumoftheyear.org/ratings/user-highest-rated/2026/rock/
2026-02-20 22:56:24 [production] INFO: Total unique genres found: 1
2026-02-20 22:56:26 [production] INFO: 
Parsing ratings page: Rock - 2026
2026-02-20 22:56:26 [production] INFO: URL: https://www.albumoftheyear.org/ratings/user-highest-rated/2026/rock/
2026-02-20 22:56:26 [production] INFO: Found 25 album links on this page
2026-02-20 22:56:26 [production] INFO: Will scrape 2 albums from this page
2026-02-20 22:56:26 [production] INFO:   [1/2] Album: https://www.albumoftheyear.org/album/1611085-wait-what-did-you-say-stay-safe-little-one.php
2026-02-20 22:56:26 [production] INFO:   [2/2] Album: https://www.albumoftheyear.org/album/1614944-mydreamfever-4-mountain-still-breathing.php
2026-02-20 22:56:28 [production] INFO: 
[Album 2] Parsing: https://www.albumoftheyear.org/album/1614944-mydreamfever-4-mountain-still-breathing.php
2026-02-20 22:56:28 [production] INFO:   Genre: Rock, Year: 2026
2026-02-20 22:56:28 [production] INFO:   ✓ Extracted: 4. Mountain Still Breathing by Mydreamfever
2026-02-20 22:56:28 [production] INFO:   Total albums scraped: 1
2026-02-20 22:56:32 [production] INFO: 
[Album 1] Parsing: https://www.albumoftheyear.org/album/1611085-wait-what-did-you-say-stay-safe-little-one.php
2026-02-20 22:56:32 [production] INFO:   Genre: Rock, Year: 2026
2026-02-20 22:56:32 [production] INFO:   ✓ Extracted: Stay Safe, Little One. by Wait, What Did You Say?
2026-02-20 22:56:32 [production] INFO:   Total albums scraped: 2
2026-02-20 22:56:32 [scrapy.core.engine] INFO: Closing spider (finished)
2026-02-20 22:56:32 [aoty_crawler.pipelines] INFO: Saved 2 albums to data/output\albums_20260221_035632.json
2026-02-20 22:56:32 [aoty_crawler.pipelines] INFO: === File Storage Complete ===
2026-02-20 22:56:32 [aoty_crawler.pipelines] INFO: Total items saved to data/output
2026-02-20 22:56:32 [production] INFO: 
============================================================
2026-02-20 22:56:32 [production] INFO: SCRAPING COMPLETE!
2026-02-20 22:56:32 [production] INFO: ============================================================
2026-02-20 22:56:32 [production] INFO: Total albums scraped: 2
2026-02-20 22:56:32 [production] INFO: Total genres processed: 0
2026-02-20 22:56:32 [production] INFO: Finish reason: finished
2026-02-20 22:56:32 [production] INFO: ============================================================
2026-02-20 22:56:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2032,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 57975,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 12.939434,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2026, 2, 21, 3, 56, 32, 818470, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 338010,
 'httpcompression/response_count': 5,
 'item_scraped_count': 2,
 'items_per_minute': 10.0,
 'log_count/INFO': 32,
 'request_depth_max': 2,
 'response_received_count': 5,
 'responses_per_minute': 25.0,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2026, 2, 21, 3, 56, 19, 879036, tzinfo=datetime.timezone.utc)}
2026-02-20 22:56:32 [scrapy.core.engine] INFO: Spider closed (finished)
2026-02-20 22:56:37 [scrapy.utils.log] INFO: Scrapy 2.14.1 started (bot: aoty_crawler)
2026-02-20 22:56:37 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.11.9',
 'cssselect': '1.4.0',
 'parsel': '1.11.0',
 'w3lib': '2.4.0',
 'Twisted': '25.5.0',
 'Python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.5 27 Jan 2026)',
 'cryptography': '46.0.5',
 'Platform': 'Windows-10-10.0.19045-SP0'}
2026-02-20 22:56:37 [production] INFO: 
============================================================
2026-02-20 22:56:37 [production] INFO: PRODUCTION SPIDER CONFIGURATION
2026-02-20 22:56:37 [production] INFO: ============================================================
2026-02-20 22:56:37 [production] INFO: Target Genre: ALL GENRES
2026-02-20 22:56:37 [production] INFO: Year Range: 2026 to 2026
2026-02-20 22:56:37 [production] INFO: Albums per Year: 2
2026-02-20 22:56:37 [production] INFO: Test Mode: True
2026-02-20 22:56:37 [production] INFO: ============================================================

2026-02-20 22:56:37 [scrapy.addons] INFO: Enabled addons:
[]
2026-02-20 22:56:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logcount.LogCount',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2026-02-20 22:56:37 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 10,
 'AUTOTHROTTLE_START_DELAY': 3,
 'BOT_NAME': 'aoty_crawler',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 3,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '-',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'aoty_crawler.spiders',
 'RETRY_HTTP_CODES': [500, 502, 503, 504, 522, 524, 408, 429, 403],
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['aoty_crawler.spiders'],
 'TELNETCONSOLE_ENABLED': False,
 'USER_AGENT': 'AOTY-Production-Spider/1.0 (Music Data Collection)'}
2026-02-20 22:56:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'aoty_crawler.middlewares.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'aoty_crawler.middlewares.RetryWithDelayMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:44: ScrapyDeprecationWarning: SeleniumMiddleware.process_request() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_request)

2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:47: ScrapyDeprecationWarning: RetryWithDelayMiddleware.process_response() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_response)

2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:50: ScrapyDeprecationWarning: RetryWithDelayMiddleware.process_exception() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_exception)

2026-02-20 22:56:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2026-02-20 22:56:37 [scrapy.middleware] INFO: Enabled item pipelines:
['aoty_crawler.pipelines.FileStoragePipeline',
 'aoty_crawler.pipelines.DuplicateCheckPipeline']
2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:44: ScrapyDeprecationWarning: FileStoragePipeline.close_spider() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.close_spider)

2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:47: ScrapyDeprecationWarning: FileStoragePipeline.process_item() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.process_item)

2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:47: ScrapyDeprecationWarning: DuplicateCheckPipeline.process_item() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.process_item)

2026-02-20 22:56:37 [scrapy.core.engine] INFO: Spider opened
2026-02-20 22:56:37 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\spidermw.py:490: ScrapyDeprecationWarning: aoty_crawler.spiders.production_spider.ProductionSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2026-02-20 22:56:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2026-02-20 22:56:37 [production] INFO: Starting at genre page: https://www.albumoftheyear.org/genre.php
2026-02-20 22:56:42 [production] INFO: Parsing genre page: https://www.albumoftheyear.org/genre.php
2026-02-20 22:56:42 [production] INFO: Found 89 genre links
2026-02-20 22:56:42 [production] INFO: Found genre: Rock (slug: rock)
2026-02-20 22:56:42 [production] INFO:   → Year 2026: https://www.albumoftheyear.org/ratings/user-highest-rated/2026/rock/
2026-02-20 22:56:42 [production] INFO: Total unique genres found: 1
2026-02-20 22:56:44 [production] INFO: 
Parsing ratings page: Rock - 2026
2026-02-20 22:56:44 [production] INFO: URL: https://www.albumoftheyear.org/ratings/user-highest-rated/2026/rock/
2026-02-20 22:56:44 [production] INFO: Found 25 album links on this page
2026-02-20 22:56:44 [production] INFO: Will scrape 2 albums from this page
2026-02-20 22:56:44 [production] INFO:   [1/2] Album: https://www.albumoftheyear.org/album/1611085-wait-what-did-you-say-stay-safe-little-one.php
2026-02-20 22:56:44 [production] INFO:   [2/2] Album: https://www.albumoftheyear.org/album/1614944-mydreamfever-4-mountain-still-breathing.php
2026-02-20 22:56:48 [production] INFO: 
[Album 2] Parsing: https://www.albumoftheyear.org/album/1614944-mydreamfever-4-mountain-still-breathing.php
2026-02-20 22:56:48 [production] INFO:   Genre: Rock, Year: 2026
2026-02-20 22:56:48 [production] INFO:   ✓ Extracted: 4. Mountain Still Breathing by Mydreamfever
2026-02-20 22:56:48 [production] INFO:   Total albums scraped: 1
2026-02-20 22:56:52 [production] INFO: 
[Album 1] Parsing: https://www.albumoftheyear.org/album/1611085-wait-what-did-you-say-stay-safe-little-one.php
2026-02-20 22:56:52 [production] INFO:   Genre: Rock, Year: 2026
2026-02-20 22:56:52 [production] INFO:   ✓ Extracted: Stay Safe, Little One. by Wait, What Did You Say?
2026-02-20 22:56:52 [production] INFO:   Total albums scraped: 2
2026-02-20 22:56:52 [scrapy.core.engine] INFO: Closing spider (finished)
2026-02-20 22:56:52 [aoty_crawler.pipelines] INFO: Saved 2 albums to data/output\albums_20260221_035652.json
2026-02-20 22:56:52 [aoty_crawler.pipelines] INFO: === File Storage Complete ===
2026-02-20 22:56:52 [aoty_crawler.pipelines] INFO: Total items saved to data/output
2026-02-20 22:56:52 [production] INFO: 
============================================================
2026-02-20 22:56:52 [production] INFO: SCRAPING COMPLETE!
2026-02-20 22:56:52 [production] INFO: ============================================================
2026-02-20 22:56:52 [production] INFO: Total albums scraped: 2
2026-02-20 22:56:52 [production] INFO: Total genres processed: 0
2026-02-20 22:56:52 [production] INFO: Finish reason: finished
2026-02-20 22:56:52 [production] INFO: ============================================================
2026-02-20 22:56:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2032,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 57979,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 15.238781,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2026, 2, 21, 3, 56, 52, 517056, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 338010,
 'httpcompression/response_count': 5,
 'item_scraped_count': 2,
 'items_per_minute': 8.0,
 'log_count/INFO': 32,
 'request_depth_max': 2,
 'response_received_count': 5,
 'responses_per_minute': 20.0,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2026, 2, 21, 3, 56, 37, 278275, tzinfo=datetime.timezone.utc)}
2026-02-20 22:56:52 [scrapy.core.engine] INFO: Spider closed (finished)
2026-02-20 22:58:26 [scrapy.utils.log] INFO: Scrapy 2.14.1 started (bot: aoty_crawler)
2026-02-20 22:58:26 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.11.9',
 'cssselect': '1.4.0',
 'parsel': '1.11.0',
 'w3lib': '2.4.0',
 'Twisted': '25.5.0',
 'Python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.5 27 Jan 2026)',
 'cryptography': '46.0.5',
 'Platform': 'Windows-10-10.0.19045-SP0'}
2026-02-20 22:58:26 [production] INFO: 
============================================================
2026-02-20 22:58:26 [production] INFO: PRODUCTION SPIDER CONFIGURATION
2026-02-20 22:58:26 [production] INFO: ============================================================
2026-02-20 22:58:26 [production] INFO: Target Genre: ALL GENRES
2026-02-20 22:58:26 [production] INFO: Year Range: 2026 to 2026
2026-02-20 22:58:26 [production] INFO: Albums per Year: 2
2026-02-20 22:58:26 [production] INFO: Test Mode: True
2026-02-20 22:58:26 [production] INFO: ============================================================

2026-02-20 22:58:26 [scrapy.addons] INFO: Enabled addons:
[]
2026-02-20 22:58:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logcount.LogCount',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2026-02-20 22:58:26 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 10,
 'AUTOTHROTTLE_START_DELAY': 3,
 'BOT_NAME': 'aoty_crawler',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 3,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '-',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'aoty_crawler.spiders',
 'RETRY_HTTP_CODES': [500, 502, 503, 504, 522, 524, 408, 429, 403],
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['aoty_crawler.spiders'],
 'TELNETCONSOLE_ENABLED': False,
 'USER_AGENT': 'AOTY-Production-Spider/1.0 (Music Data Collection)'}
2026-02-20 22:58:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'aoty_crawler.middlewares.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'aoty_crawler.middlewares.RetryWithDelayMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:44: ScrapyDeprecationWarning: SeleniumMiddleware.process_request() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_request)

2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:47: ScrapyDeprecationWarning: RetryWithDelayMiddleware.process_response() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_response)

2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\downloader\middleware.py:50: ScrapyDeprecationWarning: RetryWithDelayMiddleware.process_exception() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(mw.process_exception)

2026-02-20 22:58:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2026-02-20 22:58:26 [scrapy.middleware] INFO: Enabled item pipelines:
['aoty_crawler.pipelines.FileStoragePipeline',
 'aoty_crawler.pipelines.DuplicateCheckPipeline']
2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:44: ScrapyDeprecationWarning: FileStoragePipeline.close_spider() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.close_spider)

2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:47: ScrapyDeprecationWarning: FileStoragePipeline.process_item() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.process_item)

2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\pipelines\__init__.py:47: ScrapyDeprecationWarning: DuplicateCheckPipeline.process_item() requires a spider argument, this is deprecated and the argument will not be passed in future Scrapy versions. If you need to access the spider instance you can save the crawler instance passed to from_crawler() and use its spider attribute.
  self._check_mw_method_spider_arg(pipe.process_item)

2026-02-20 22:58:26 [scrapy.core.engine] INFO: Spider opened
2026-02-20 22:58:26 [py.warnings] WARNING: C:\Python310\lib\site-packages\scrapy\core\spidermw.py:490: ScrapyDeprecationWarning: aoty_crawler.spiders.production_spider.ProductionSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2026-02-20 22:58:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2026-02-20 22:58:26 [production] INFO: Starting at genre page: https://www.albumoftheyear.org/genre.php
2026-02-20 22:58:31 [production] INFO: Parsing genre page: https://www.albumoftheyear.org/genre.php
2026-02-20 22:58:31 [production] INFO: Found 89 genre links
2026-02-20 22:58:31 [production] INFO: Found genre: Rock (slug: rock)
2026-02-20 22:58:31 [production] INFO:   → Year 2026: https://www.albumoftheyear.org/ratings/user-highest-rated/2026/rock/
2026-02-20 22:58:31 [production] INFO: Total unique genres found: 1
2026-02-20 22:58:34 [production] INFO: 
Parsing ratings page: Rock - 2026
2026-02-20 22:58:34 [production] INFO: URL: https://www.albumoftheyear.org/ratings/user-highest-rated/2026/rock/
2026-02-20 22:58:34 [production] INFO: Found 25 album links on this page
2026-02-20 22:58:34 [production] INFO: Will scrape 2 albums from this page
2026-02-20 22:58:34 [production] INFO:   [1/2] Album: https://www.albumoftheyear.org/album/1611085-wait-what-did-you-say-stay-safe-little-one.php
2026-02-20 22:58:34 [production] INFO:   [2/2] Album: https://www.albumoftheyear.org/album/1614944-mydreamfever-4-mountain-still-breathing.php
2026-02-20 22:58:38 [production] INFO: 
[Album 2] Parsing: https://www.albumoftheyear.org/album/1614944-mydreamfever-4-mountain-still-breathing.php
2026-02-20 22:58:38 [production] INFO:   Genre: Rock, Year: 2026
2026-02-20 22:58:38 [production] INFO:   ✓ Extracted: 4. Mountain Still Breathing by Mydreamfever
2026-02-20 22:58:38 [production] INFO:   Total albums scraped: 1
2026-02-20 22:58:42 [production] INFO: 
[Album 1] Parsing: https://www.albumoftheyear.org/album/1611085-wait-what-did-you-say-stay-safe-little-one.php
2026-02-20 22:58:42 [production] INFO:   Genre: Rock, Year: 2026
2026-02-20 22:58:42 [production] INFO:   ✓ Extracted: Stay Safe, Little One. by Wait, What Did You Say?
2026-02-20 22:58:42 [production] INFO:   Total albums scraped: 2
2026-02-20 22:58:42 [scrapy.core.engine] INFO: Closing spider (finished)
2026-02-20 22:58:42 [aoty_crawler.pipelines] INFO: Saved 2 albums to data/output\albums_20260221_035842.json
2026-02-20 22:58:42 [aoty_crawler.pipelines] INFO: === File Storage Complete ===
2026-02-20 22:58:42 [aoty_crawler.pipelines] INFO: Total items saved to data/output
2026-02-20 22:58:42 [production] INFO: 
============================================================
2026-02-20 22:58:42 [production] INFO: SCRAPING COMPLETE!
2026-02-20 22:58:42 [production] INFO: ============================================================
2026-02-20 22:58:42 [production] INFO: Total albums scraped: 2
2026-02-20 22:58:42 [production] INFO: Total genres processed: 0
2026-02-20 22:58:42 [production] INFO: Finish reason: finished
2026-02-20 22:58:42 [production] INFO: ============================================================
2026-02-20 22:58:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2032,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 57982,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 15.971774,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2026, 2, 21, 3, 58, 42, 696243, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 338010,
 'httpcompression/response_count': 5,
 'item_scraped_count': 2,
 'items_per_minute': 8.0,
 'log_count/INFO': 32,
 'request_depth_max': 2,
 'response_received_count': 5,
 'responses_per_minute': 20.0,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2026, 2, 21, 3, 58, 26, 724469, tzinfo=datetime.timezone.utc)}
2026-02-20 22:58:42 [scrapy.core.engine] INFO: Spider closed (finished)
